{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96a98a57",
   "metadata": {},
   "source": [
    "# TrustyAI\n",
    "By testing our model after training and before it goes into production, we get a good understand on how well the model performs on data which we currently have available.  \n",
    "Unfortunatly, the real world is not very simple and things are constantly changing, so what we took for granted yesterday may look completely different today. Because of this, we need to monitor if changes in the world has an impact on our models ability to make accurate predictions.  \n",
    "We want to track key metrics that can indicate if the model or the data starts behaving strangely once the model is in production and sees live data.  \n",
    "For this, we have a tool called TrustyAI that can help us generate metrics for fairness and drift detection. With TrustyAI, we can determine if live data differs from what we expected when we created our training dataset. It allows us to measure whether our model responds to real-world data differently than we initially anticipated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f001996f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install onnxruntime model-registry==0.2.10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81df644",
   "metadata": {},
   "source": [
    "### Get your User token\n",
    "We need to provide our user token so that the workbench can send request to our TrustyAI Service.\n",
    "You can get the user token by:\n",
    "1. Going to the OpenShift Console\n",
    "2. Click the dropdown in the top right corner where your username is displayed\n",
    "3. Choose \"Copy login command\"\n",
    "4. Log in\n",
    "5. Select the part in the first code box after `token`, it should look something like `sha256~.....`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202acbc3-aabf-40c1-b168-6b0adfd0edf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "infer_endpoint = \"ENTER-YOUR-INFERENCE-ENDPOINT\"\n",
    "token = \"ENTER-YOUR-TOKEN\"\n",
    "model_version = \"ENTER-YOUR-MODEL-VERSION\"\n",
    "cluster_domain = \"ENTER-YOUR-CLUSTER-DOMAIN\"\n",
    "\n",
    "model_name = \"jukebox\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd850481",
   "metadata": {},
   "outputs": [],
   "source": [
    "namespace_file_path =\\\n",
    "    '/var/run/secrets/kubernetes.io/serviceaccount/namespace'\n",
    "with open(namespace_file_path, 'r') as namespace_file:\n",
    "    current_namespace = namespace_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4a0deb3-2a9c-4cdb-8936-41f4cd4adb9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "import onnxruntime as rt\n",
    "import numpy as np\n",
    "import onnx\n",
    "\n",
    "import requests\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ef25da",
   "metadata": {},
   "source": [
    "### Data\n",
    "We are going to send our training data to the TrustyAI Service so that it can compare the training data with the new data coming in from our inference requests.  \n",
    "We limit it to just 5000 samples to keep it light, but in a real usecase you would send your full training data, or a part of it that properly represented its distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37cf1e2-4d4c-463f-ac73-2288fc3d6909",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_pickle('train_data.pkl')[0][:5000]\n",
    "\n",
    "with open(\"scaler.pkl\", 'rb') as handle:\n",
    "    scaler = pickle.load(handle)\n",
    "data = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d40101",
   "metadata": {},
   "source": [
    "We also get the predictions of the data so that we can see if they start drifting as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78c55ac-e954-4fcd-9de3-ab4d7a1e8152",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sess = rt.InferenceSession(\"onnx_model.onnx\", providers=rt.get_available_providers())\n",
    "input_name = sess.get_inputs()[0].name\n",
    "output_name = sess.get_outputs()[0].name\n",
    "y_pred_temp = sess.run([output_name], {input_name: data.astype(np.float32).tolist()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d290a4dc",
   "metadata": {},
   "source": [
    "After we have all our data, we structure it in a specific way that TrustyAI expects.  \n",
    "Noteably, we add a data_tag to our data, so that we can keep track of different iterations of it or data that's used for different purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7e09f88-1b5f-4e47-bcfb-09866232bc08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_data = {\n",
    "    \"model_name\": model_name,\n",
    "    \"data_tag\": \"TRAINING\",\n",
    "    \"request\": {\n",
    "        \"inputs\": [\n",
    "            {\n",
    "                \"name\": input_name,\n",
    "                \"shape\": np.shape(data),\n",
    "                \"datatype\": \"FP32\",\n",
    "                \"data\": data.tolist()\n",
    "            }\n",
    "        ]    \n",
    "    },\n",
    "    \"response\": {\n",
    "        \"model_name\": model_name,\n",
    "        \"model_version\": \"1\",\n",
    "        \"outputs\": [\n",
    "            {\n",
    "                \"name\": output_name,\n",
    "                \"datatype\": \"FP32\",\n",
    "                \"shape\": np.shape(y_pred_temp[0]),\n",
    "                \"data\": y_pred_temp[0].tolist()\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05203dbc",
   "metadata": {},
   "source": [
    "### Interacting with TrustyAI through requests\n",
    "We will be interacting with our TrustyAI Service through rest requests.  \n",
    "Before we can do that though, we need to add our TrustyAI Service Route as the `base_url` so we know where to send the requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7705b44-e0e9-4b96-bbff-81bbce4079fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_url = f\"http://trustyai-service.{current_namespace}-test.svc.cluster.local\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {token}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cad44fa",
   "metadata": {},
   "source": [
    "First thing we do is upload the data which we have prepared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e88b79f4-1788-424c-864d-4af919daec43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 datapoints successfully added to jukebox data.\n"
     ]
    }
   ],
   "source": [
    "# Upload data\n",
    "endpoint = \"data/upload\"\n",
    "url = urljoin(base_url, endpoint)\n",
    "response = requests.post(url, headers=headers, json=training_data)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc1576c",
   "metadata": {},
   "source": [
    "Then we change the names of the inputs. By default they will just be the input-layer name with a number behind them, but in our case we can change them to the actual feature names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcb5cd9-4fa8-4af4-bdef-4773a6218694",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change the input and output names\n",
    "endpoint = \"info/names\"\n",
    "url = urljoin(base_url, endpoint)\n",
    "\n",
    "payload = {\n",
    "    \"modelId\": model_name,\n",
    "    \"inputMapping\": {\n",
    "        f\"{input_name}-0\": \"is_explicit\",\n",
    "        f\"{input_name}-1\": \"duration_ms\",\n",
    "        f\"{input_name}-2\": \"danceability\",\n",
    "        f\"{input_name}-3\": \"energy\",\n",
    "        f\"{input_name}-4\": \"key\",\n",
    "        f\"{input_name}-5\": \"loudness\",\n",
    "        f\"{input_name}-6\": \"mode\",\n",
    "        f\"{input_name}-7\": \"speechiness\",\n",
    "        f\"{input_name}-8\": \"acousticness\",\n",
    "        f\"{input_name}-9\": \"instrumentalness\",\n",
    "        f\"{input_name}-10\": \"liveness\",\n",
    "        f\"{input_name}-11\": \"valence\",\n",
    "        f\"{input_name}-12\": \"tempo\"\n",
    "    },\n",
    "    \"outputMapping\": {\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=payload)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e531e7b2",
   "metadata": {},
   "source": [
    "Now we can subscribe to our drift detection metric which will cause our TrustyAI Service to continously publish drift (specifically meanshift) metrics.  \n",
    "\n",
    "The meanshift metric track how different the distribution of the training data looks like compared to the new data we send it.  \n",
    "\n",
    "For each individual input and output feature we will get a \"p-value\" between 0 and 1. A p-value of 1.0 indicates a very high likelihood that the train and test data come from the same distribution, while a p-value < 0.05 indicates a statistically significant drift between train and test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96ea7a1-3e4a-4d2b-abec-fc46e0330cf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Monitor meanshift\n",
    "endpoint = \"/metrics/drift/meanshift/request\"\n",
    "url = urljoin(base_url, endpoint)\n",
    "\n",
    "payload = {\n",
    "    \"modelId\": model_name,\n",
    "    \"referenceTag\": \"TRAINING\"\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=payload)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853c55b7",
   "metadata": {},
   "source": [
    "To make sure all looks correct, we can ask the TrustyAI Service how our current setup looks like.  \n",
    "We will get back information on what metrics we have subscribed to, as well as what data has been added.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2024b207-c705-4cc2-9b27-ebab030a29ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# See what we have registered\n",
    "endpoint = \"/info\"\n",
    "url = urljoin(base_url, endpoint)\n",
    "response = requests.get(url, headers=headers)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e3ecf6",
   "metadata": {},
   "source": [
    "### Send a request\n",
    "Finally, we need to send a single request to our model server for TrustyAI to start publishing the metrics. This is so that it has at least one inference datapoint to compare its training data to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b667e590",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_url = f\"{infer_endpoint}/v2/models/{model_name}/infer\"\n",
    "\n",
    "def rest_request(data):\n",
    "    json_data = {\n",
    "        \"inputs\": [\n",
    "            {\n",
    "                \"name\": input_name,\n",
    "                \"shape\": [1, 13],\n",
    "                \"datatype\": \"FP32\",\n",
    "                \"data\": data\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    response = requests.post(infer_url, json=json_data, verify=True)\n",
    "    response_dict = response.json()\n",
    "    return response_dict['outputs'][0]['data']\n",
    "\n",
    "prediction = rest_request(data[0].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d555704",
   "metadata": {},
   "source": [
    "Additonally, we can also monitor the avearage value of any feature to see how it changes over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a323695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor the average value\n",
    "endpoint = \"/metrics/identity/request\"\n",
    "url = urljoin(base_url, endpoint)\n",
    "\n",
    "payload = {\n",
    "    \"modelId\": model_name,\n",
    "    \"columnName\": \"duration_ms\",\n",
    "    \"batchSize\": 256,\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=payload)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7875c597",
   "metadata": {},
   "source": [
    "Let's go to the next Notebook to create some drift and observe the metrics in OpenShift UI ðŸ‘‰ [jukebox/4-metrics/2-introducing_drift.ipynb](2-introducing_drift.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
