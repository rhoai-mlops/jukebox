{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c23b0470-4411-4e38-aa12-4d8e94bce91e",
   "metadata": {},
   "source": [
    "## üêà Building the model\n",
    "\n",
    "In the journey of building a machine learning model, one of the first decisions is choosing the right type of model‚Äîpredictive or generative. Predictive models focus on forecasting outcomes based on input data, while generative models aim to learn the underlying distribution of data to generate new samples.\n",
    "\n",
    "Our usecase is categorized under predictive machine learning. There are many different ways to build a predictive model. For our use case, we chose neural networks. It has the ability to generalize better, handle complex patterns, and more expressive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c43f41-d612-4ef4-ba0d-7123dee92738",
   "metadata": {},
   "source": [
    "## üê† Install & Import packages\n",
    "\n",
    "Again, we will need to install and import packages as we develop our notebook.\n",
    "\n",
    "This will take a couple of minutes, and if `pip` gives an Error, don't worry about it. Things will just run fine regardless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c47fb1-3f55-469e-b9f1-ab2a8595a1e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip -q install keras \"tensorflow==2.15.1\" \"tf2onnx\" \"onnx\" \"seaborn\" \"onnxruntime\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a801f7dd-604c-4b45-82ad-2ee572ed9372",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "import os\n",
    "import logging, warnings\n",
    "\n",
    "# Suppress warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation, Input, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "import tf2onnx\n",
    "import onnx\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import onnxruntime as rt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d92117d-f726-4c71-b9fb-fef61bd957ff",
   "metadata": {},
   "source": [
    "# üì¶ Load Data\n",
    "\n",
    "We again load our two datasets, merge them, drop the NA columns just like before and select the input and output data.\n",
    "\n",
    "Input data (X) is the feature matrix that contains the characteristics of each song.\n",
    "\n",
    "Output data (y)is the target variable the model is trying to predict. In this case, y is the 'country' column which represents the country where the song is popular. The model will learn to predict the country based on the song features in X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cc19be-13b7-4063-ae74-08f2400e492f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "song_properties = pd.read_parquet('https://github.com/rhoai-mlops/jukebox/raw/refs/heads/main/99-data_prep/song_properties.parquet')\n",
    "song_rankings = pd.read_parquet('https://github.com/rhoai-mlops/jukebox/raw/refs/heads/main/99-data_prep/song_rankings.parquet')\n",
    "song_properties.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b38b8a-07f3-4c08-9d48-026e843013f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove missing values (NaNs) from the dataset\n",
    "song_rankings = song_rankings.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851fc269-bd9b-4303-b79b-1554e5c66a60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X is the input fetures we want to train the model on while y is the output feature we want the model to predict.\n",
    "X = song_rankings.merge(song_properties, on='spotify_id', how='left')\n",
    "X = X[['is_explicit', 'duration_ms', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']]\n",
    "y = song_rankings['country']\n",
    "\n",
    "# We use a label encoder to get numbers instead of country codes\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_one_hot = tf.keras.utils.to_categorical(y_encoded)\n",
    "\n",
    "# Split the data into training and testing sets so you have something to test the trained model with.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size = 0.2, shuffle = False, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train, test_size = 0.2, stratify = y_train, random_state=42)\n",
    "\n",
    "# Scale the data to remove mean and have unit variance. The data will be between -1 and 1, which makes it a lot easier \n",
    "# for the model to learn than random (and potentially large) values.\n",
    "# It is important to only fit the scaler to the training data, otherwise you are leaking information about the global \n",
    "# distribution of variables (which is influenced by the test set) into the training set.\n",
    "scaler = MinMaxScaler()\n",
    "scaled_x_train = pd.DataFrame(scaler.fit_transform(X_train), index=X_train.index, columns=X_train.columns)\n",
    "scaled_x_val = pd.DataFrame(scaler.transform(X_val), index=X_val.index, columns=X_val.columns)\n",
    "scaled_x_test = pd.DataFrame(scaler.transform(X_test), index=X_test.index, columns=X_test.columns).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67168c8-2dd1-4557-a6c3-13f6a4ed63dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# üõü Prepare to save the model\n",
    "\n",
    "Before we start building neural network and training the model, let's prepare the environment to store the resulting artifacts. \n",
    "\n",
    "We need to store our model artifacts in an S3 buckets with folder called models/model-name/version/ for versioning reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c1a425-8c72-4abb-ae81-fb86971e0718",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create local directories to save the model artifacts before starting building neural network and training the model\n",
    "Path(\"models/jukebox/1/artifacts\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(\"models/jukebox/1/artifacts/scaler.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(scaler, handle)\n",
    "\n",
    "with open(\"models/jukebox/1/artifacts/label_encoder.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(label_encoder, handle)\n",
    "\n",
    "with open(\"models/jukebox/1/artifacts/y_test.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(y_test, handle)\n",
    "\n",
    "X_train.to_parquet(\"models/jukebox/1/artifacts/X_train.parquet\")\n",
    "X_test.to_parquet(\"models/jukebox/1/artifacts/X_test.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49579786-b17a-406b-a9ff-069f822c9fa1",
   "metadata": {},
   "source": [
    "# üöÄ Build the model\n",
    "\n",
    "The below piece of code is like creating a smart helper (aka Model) that learns to guess which country might like a song based on its features. To process these features, our helper will pass them through multiple layers of \"neurons\". These work much like in our brain and the more layers and neurons it has, the more capacity it has for learning.\n",
    "\n",
    "At the end, our little helper uses what it learned to predict the country that would enjoy the song the most. \n",
    "\n",
    "Finally, we check how well our helper is doing at making these guesses!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c988d274-a415-49a3-99a1-caa2b610d7d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Have a dense layer for each individual input?\n",
    "inputs = [Input(shape=(1,), name=name) for name in X.columns]\n",
    "concatenated_inputs = Concatenate(name=\"input\")(inputs)\n",
    "x = Dense(32, activation='relu', name=\"dense_0\")(concatenated_inputs)\n",
    "x = Dense(64, name=\"dense_1\")(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(128, name=\"dense_2\")(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(256, name=\"dense_3\")(x)\n",
    "x = Activation('relu')(x)\n",
    "output = Dense(y_one_hot.shape[1], activation='sigmoid', name=\"dense_4\")(x)\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', 'Precision', 'Recall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daf4f12-9802-4bfa-bb79-4043550604a3",
   "metadata": {},
   "source": [
    "# üèÉ Train the Model\n",
    "\n",
    "Now we train our smart helper to predict which country might like a song based on its features. We set it to learn from the training data for 2 epochs, which means that it sees the full dataset two times. During each round, it looks at the song characteristics (scaled_x_train) and the country labels (y_train). It also predicts on a separate dataset called the validation dataset (X_val and y_val) after each epoch. This is to see how well it does on data it hasn't trained on yet.\n",
    "Remember we split the data into three in an above cell. That was the reason :)\n",
    "\n",
    "Once the training is finished, we print a message to let us know that our model is ready to make predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079ac597",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = {name: scaled_x_train[[name]].to_numpy() for name in X_train.columns}\n",
    "val_inputs = {name: scaled_x_val[[name]].to_numpy() for name in X_val.columns}\n",
    "test_inputs = {name: scaled_x_test[[name]].to_numpy() for name in X_test.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc19448c-6525-4e32-9b32-69641978fb27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "history = model.fit(\n",
    "    train_inputs,\n",
    "    y_train,\n",
    "    epochs=epochs,\n",
    "    validation_data=(val_inputs, y_val),\n",
    "    verbose=True\n",
    ")\n",
    "print(\"Training of model is complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6ed20d-3f7c-45a2-827a-cd8d36acd967",
   "metadata": {},
   "source": [
    "# ü´° Save the Model\n",
    "\n",
    "Here we convert our trained song prediction model into a popular format called ONNX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c36515-4bf9-4017-bfb9-71ab3d8966e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_signature = [tf.TensorSpec(i.shape, i.dtype, i.name) for i in model.inputs]\n",
    "model.output_names = ['output']\n",
    "onnx_model_proto, _ = tf2onnx.convert.from_keras(model, input_signature)\n",
    "onnx.save(onnx_model_proto, \"models/jukebox/1/model.onnx\")\n",
    "\n",
    "model.save('models/jukebox/1/model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835b8f29-b610-414d-b1e3-e76d3ea38093",
   "metadata": {},
   "source": [
    "### Quiz Time ü§ì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a0e505-1bfa-47b9-9570-0ee47b5fe8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../.dontlookhere/'))\n",
    "from quiz2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c03ff3f-8ee1-447c-a89f-8ec47000f27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72254830-e3df-46ea-93f0-8c63065a2a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_nn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3265f960-a706-44fb-bd8c-3b6dd1d7e336",
   "metadata": {},
   "source": [
    "# üî• Load the Model for Testing\n",
    "\n",
    "Here we load the model to predict which country might like a song. We open a session to the model and feed in the test data (X_test). The model outputs predictions, and identifies the countries.\n",
    "\n",
    "The accuracy is calculated by comparing the predicted countries to the actual ones as we have the actual answers in our data. That's how we get the accuracy metrics.\n",
    "\n",
    "We also create a confusion matrix to visualize the prediction results, using a heatmap to show how well the model's predictions match the actual labels. We want the predicted country to be the same as the actual country as much as possible, which is visualized by having dark squares on the diagonal, so that for example country 0 often is predicted as country 0 (not as any other country).\n",
    "In other words, the darker the diagonal line, the closer we get to good predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576e0946-0e36-42ac-821f-284949f1548c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sess = rt.InferenceSession(\"models/jukebox/1/model.onnx\", providers=rt.get_available_providers())\n",
    "output_name = sess.get_outputs()[0].name\n",
    "y_pred_temp = sess.run([output_name], test_inputs)\n",
    "y_pred_temp = y_pred_temp[0]\n",
    "y_pred_argmax = np.argmax(y_pred_temp, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a251400f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_test_argmax = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e216592",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy = np.sum(y_pred_argmax == y_test_argmax) / len(y_pred_argmax)\n",
    "print(\"Accuracy: \" + str(accuracy))\n",
    "\n",
    "c_matrix = confusion_matrix(y_test_argmax,y_pred_argmax)\n",
    "ax = sns.heatmap(c_matrix, cmap='Blues')\n",
    "ax.set_xlabel(\"Prediction\")\n",
    "ax.set_ylabel(\"Actual\")\n",
    "ax.set_title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87250c39-6c44-453a-bd27-91408f42a1c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "And now we need to save the model in our S3 bucket to make it available outside of this Notebook. So please open up the [2-save_model.ipynb](2-save_model.ipynb) :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
