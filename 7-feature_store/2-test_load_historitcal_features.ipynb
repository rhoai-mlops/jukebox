{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfdf04eb",
   "metadata": {},
   "source": [
    "## üìÇ Offline Features\n",
    "\n",
    "With our features now registered, we can use them to create a **training dataset** by fetching the defined features from the **Offline Store**. \n",
    "\n",
    "In this example, we'll retrieve the **full dataset** with all available features. However, as we‚Äôll explore in this notebook, we can easily:\n",
    "- Select **specific features** instead of the full set.\n",
    "- Combine features from **different FeatureViews**.\n",
    "- Filter data based on a **specific time window**.\n",
    "\n",
    "This flexibility allows us to tailor the dataset to the needs of our machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac95bf91",
   "metadata": {},
   "source": [
    "## üì¶ Importing Dependencies\n",
    "Before working with Feast, we need to import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ba4341-f808-4667-bd7b-d9c3df00967b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import feast\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import psycopg2\n",
    "import yaml\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c48b7c0",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Loading the Feature Store Configuration  \n",
    "\n",
    "As we saw previously, before we can interact with **Feast**, we need to load its configuration from the `feature_store.yaml` file. This file defines how the Feature Store is set up, including connections to the registry, online store, and offline store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc950cb2-cf5f-4ee0-afde-60174dfd9ce5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('feature_repo/feature_store.yaml', 'r') as file:\n",
    "    fs_config_yaml = yaml.safe_load(file)\n",
    "\n",
    "fs_config = feast.repo_config.RepoConfig(**fs_config_yaml)\n",
    "fs = feast.FeatureStore(config=fs_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8c0315",
   "metadata": {},
   "source": [
    "With this code we are aiming the following:\n",
    "- Reads the **feature store configuration** from `feature_store.yaml`.\n",
    "- Initializes a **FeatureStore** object to enable feature retrieval and management.\n",
    "- Sets up the **connection** to the PostgreSQL registry and storage locations.\n",
    "\n",
    "Once this setup is complete, we can start querying feature data from the Feature Store!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d4157e",
   "metadata": {},
   "source": [
    "### Point-in-time correctness\n",
    "To get datapoints from Feast, we have to provide it with the ID we want to get features for as well as a date.  \n",
    "Feast then finds the most recent feature values before that date for the selected features. This ensures that our models don‚Äôt accidentally use future information, preventing data leakage.  \n",
    "\n",
    "In our case, we are using the song_rankings dataset to grab features from the song_properties data and merge them together.  \n",
    "Because we have multiple songs from the same date and with the same ID in the rankings dataset, we are also adding a small date delta to make sure the Feast doesn't discard any of the duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e2088b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = pd.read_parquet(\"../99-data_prep/song_rankings.parquet\")\n",
    "# Feast will remove rows with identical id and date so we add a small delta to each\n",
    "microsecond_deltas = np.arange(0, len(training_dataset))*2\n",
    "training_dataset['snapshot_date'] = training_dataset['snapshot_date'] + pd.to_timedelta(microsecond_deltas, unit='us')\n",
    "# Lets wakeup with some Espresso ‚òï and see how our data changed over time in France \n",
    "training_dataset[\n",
    "    (training_dataset['name'] == 'Espresso') &\n",
    "    (training_dataset['country'] == 'FR')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaef321",
   "metadata": {},
   "source": [
    "As we checked, we need to:\n",
    "- Load the **Parquet dataset** into a Pandas DataFrame.\n",
    "- Ensure unique **timestamp values** by adding microsecond deltas.\n",
    "- Prepare the dataset so Feast can match features using **entity keys and timestamps**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfde16c",
   "metadata": {},
   "source": [
    "## üè∑Ô∏è Selecting Features for Training  \n",
    "\n",
    "Now we can specify what features we want to get, note that we also say what Feature View those features come from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ce56f0-342a-4dbf-8bda-14922da87bde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features=[\n",
    "        \"song_properties:is_explicit\",\n",
    "        \"song_properties:duration_ms\",\n",
    "        \"song_properties:danceability\",\n",
    "        \"song_properties:energy\",\n",
    "        \"song_properties:key\",\n",
    "        \"song_properties:loudness\",\n",
    "        \"song_properties:mode\",\n",
    "        \"song_properties:speechiness\",\n",
    "        \"song_properties:acousticness\",\n",
    "        \"song_properties:instrumentalness\",\n",
    "        \"song_properties:liveness\",\n",
    "        \"song_properties:valence\",\n",
    "        \"song_properties:tempo\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c607d0d0",
   "metadata": {},
   "source": [
    "This list of features does the following:\n",
    "- Specifies **song-related features** such as `energy`, `danceability`, and `tempo`.\n",
    "- Uses the **feature naming convention** (`song_properties:<feature_name>`) to retrieve the correct data.\n",
    "- Allows flexibility in selecting features based on the **model‚Äôs needs**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61085d0",
   "metadata": {},
   "source": [
    "## üîÑ Retrieving Historical Features  \n",
    "\n",
    "Finally, we retrieve the historical feature values for our dataset from Feast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25c7a97-0f10-453e-9a49-3d99144ca44f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_df = fs.get_historical_features(entity_df=training_dataset, features=features).to_df()\n",
    "training_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367eb9f9",
   "metadata": {},
   "source": [
    "Finally, when we retrieve the historical feature values for our dataset from Feast, we are doing the following:\n",
    "- Queries the **Offline Store** to retrieve features for each song and timestamp.\n",
    "- Matches **entity keys** (e.g., song IDs) with stored features.\n",
    "- Converts the output into a **Pandas DataFrame** for easy use in training models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2d2449",
   "metadata": {},
   "source": [
    "With these steps completed, we now have a **fully-featured dataset**, enriched with historical values, ready for training! üöÄ\n",
    "\n",
    "We now know how to get training data from Feast, let's next look at how to use it during inference.  \n",
    "In the next notebook we will fetch Online Features: [3-test_load_online_features.ipynb](3-test_load_online_features.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
